{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVQB8AP6NEE8"
      },
      "source": [
        "# **Fraud** **Detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDYf7c-8NEX8"
      },
      "source": [
        "## **Objective:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETbivec6NIMA"
      },
      "source": [
        "**To predict whether a transcation was fradulent or non-fraudulent**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9XocIvoN5ZA"
      },
      "source": [
        "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XphlVDQN5je"
      },
      "source": [
        "## **Dataset:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx_0SG19OLDs"
      },
      "source": [
        "The dataset contains European cardholder transactions that occurred over two days.\n",
        "\n",
        "feature descriptions- Time - the seconds elapsed between each transaction and the first transaction in the dataset V1, V2, â€¦, V28 - principal components obtained through dimensionality reduction (PCA) Amount - the transaction amount Class - the response variable, indicating whether a transaction was fraudulent or not."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle"
      ],
      "metadata": {
        "id": "JgPZnQeVIVM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "LN38BBG_IY1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "id": "8J4hrPtUIZ0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "YzRmyxAAIl34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "xrpCE_dUIvtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "TkUnntM_I04z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets list"
      ],
      "metadata": {
        "id": "DzXGoI9KI6J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download omnia/creditcardfraud"
      ],
      "metadata": {
        "id": "_bItSV-PJKYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "id": "mGt26UpZLZKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "\n",
        "od.download(\"https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\")"
      ],
      "metadata": {
        "id": "Mc98cE8qLqeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV6eVd2LM6aD"
      },
      "source": [
        "***Importing*** ***Libraries***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_Rul7klN7mK"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy import stats\n",
        "from scipy.stats import norm, skew\n",
        "from scipy.special import boxcox1p\n",
        "from scipy.stats import boxcox_normmax\n",
        "\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score \n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
        "\n",
        "from sklearn.linear_model import Ridge,Lasso,LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "#to ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/creditcardfraud/creditcard.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "fvVhnV3QLzPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laWlSMUDc6Ag"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "qQLjtA4OMtHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "uM4FyGGmMwBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the class distribution of the target variable\n",
        "df['Class'].value_counts()"
      ],
      "metadata": {
        "id": "LAXeHiGzMwDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the class distribution of the target variable in percentage\n",
        "print(df.groupby('Class')['Class'].count()/df['Class'].count()*100)\n",
        "((df.groupby('Class')['Class'].count()/df['Class'].count())*100).plot.pie();"
      ],
      "metadata": {
        "id": "7H_ptVXCMwHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a bar plot for the number & percentage of fraudulent vs non-fradulent transaction\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.countplot(df['Class'])\n",
        "plt.title('Class Count',fontsize=18)\n",
        "plt.xlabel('Record counts by class',fontsize=15)\n",
        "plt.ylabel('Count',fontsize=15)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "2gIcPQYcMwJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the correlation\n",
        "corr =df.corr()\n",
        "corr"
      ],
      "metadata": {
        "id": "49-ypHQnMwXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check correlation in heatmap\n",
        "plt.figure(figsize=(24,18))\n",
        "\n",
        "sns.heatmap(corr, cmap=\"coolwarm\",annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IZjp4T8qOHBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#As time is given in relative fasion ,we are using pandas,Timedelta which represents a duration,the difference between two time\n",
        "Delta_Time =pd.to_timedelta(df['Time'],unit='s')\n",
        "\n",
        "#create derived columns Mins and hours\n",
        "df['Time_Day']  = (Delta_Time.dt.components.days).astype(int)\n",
        "df['Time_Hour'] = (Delta_Time.dt.components.hours).astype(int)\n",
        "df['Time_Min']  = (Delta_Time.dt.components.minutes).astype(int)"
      ],
      "metadata": {
        "id": "SjtL36UZOHDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop unnecessory columns\n",
        "#We will drop time,as we have derived the day/hour/minuted from the time column\n",
        "df.drop('Time',axis= 1,inplace=True)\n",
        "#We will keep only dervied column hour, as day/minutes might not be very useful\n",
        "df.drop(['Time_Day','Time_Min'], axis = 1,inplace = True)"
      ],
      "metadata": {
        "id": "GT4QDEO8OHKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Spliting the data into train & test data***"
      ],
      "metadata": {
        "id": "ZpxDaZoSOWEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dataset into x and y\n",
        "y = df['Class']\n",
        "X=df.drop(['Class'],axis=1)"
      ],
      "metadata": {
        "id": "MKceusFlMwbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking some row in x\n",
        "X.head()"
      ],
      "metadata": {
        "id": "W18CV7eEOnWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking some row in y\n",
        "y.head()"
      ],
      "metadata": {
        "id": "oxpn8N7kOndJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the dataset using train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y, random_state=100, test_size= 0.20 )"
      ],
      "metadata": {
        "id": "s_YPOL-LOnfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the spread of data post split\n",
        "print(np.sum(y))\n",
        "print(np.sum(y_train))\n",
        "print(np.sum(y_test))"
      ],
      "metadata": {
        "id": "EdNjc-5GOnjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the distribution of a variable"
      ],
      "metadata": {
        "id": "iCJfF_bvO5yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accumulating all the column names under one variable\n",
        "cols = list(X.columns.values)"
      ],
      "metadata": {
        "id": "ClCRS-DfOnmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the histogram of a variable from the dataset to see the skewness\n",
        "normal_records = df.Class == 0\n",
        "fraud_records = df.Class == 1\n",
        "\n",
        "plt.figure(figsize=(20, 60))\n",
        "for n, col in enumerate(cols):\n",
        "  plt.subplot(10,3,n+1)\n",
        "  sns.distplot(X[col][normal_records], color='green')\n",
        "  sns.distplot(X[col][fraud_records], color='red')\n",
        "  plt.title(col, fontsize=17)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3QYQG3cqOnpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Building**"
      ],
      "metadata": {
        "id": "KWdg6eYKPRNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a dataframe to store results\n",
        "df_Results = pd.DataFrame(columns=['Methodology','Model','Accuracy','roc_value','threshold'])"
      ],
      "metadata": {
        "id": "vd8DA9YzPLh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Created a common function to plot confusion matrix\n",
        "def Plot_confusion_matrix(y_test, pred_test):\n",
        "  cm = confusion_matrix(y_test, pred_test)\n",
        "  plt.clf()\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Accent)\n",
        "  categoryNames = ['Non-Fraudalent','Fraudalent']\n",
        "  plt.title('Confusion Matrix - Test Data')\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  ticks = np.arange(len(categoryNames))\n",
        "  plt.xticks(ticks, categoryNames, rotation=45)\n",
        "  plt.yticks(ticks, categoryNames)\n",
        "  s = [['TN','FP'], ['FN', 'TP']]\n",
        "  \n",
        "  for i in range(2):\n",
        "      for j in range(2):\n",
        "          plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]),fontsize=12)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ihzkHWmDOnsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Created a common function to fit and predict on a Logistic Regression model for both L1 and L2\n",
        "def buildAndRunLogisticModels(df_Results, Methodology, X_train,y_train, X_test, y_test ):\n",
        "\n",
        "  # Logistic Regression\n",
        "  from sklearn import linear_model\n",
        "  from sklearn.model_selection import KFold\n",
        "\n",
        "  num_C = list(np.power(10.0, np.arange(-10, 10)))\n",
        "  cv_num = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "  searchCV_l2 = linear_model.LogisticRegressionCV(\n",
        "          Cs= num_C\n",
        "          ,penalty='l2'\n",
        "          ,scoring='roc_auc'\n",
        "          ,cv=cv_num\n",
        "          ,random_state=42\n",
        "          ,max_iter=10000\n",
        "          ,fit_intercept=True\n",
        "          ,solver='newton-cg'\n",
        "          ,tol=10\n",
        "      )\n",
        "\n",
        "  searchCV_l1 = linear_model.LogisticRegressionCV(\n",
        "          Cs=num_C\n",
        "          ,penalty='l1'\n",
        "          ,scoring='roc_auc'\n",
        "          ,cv=cv_num\n",
        "          ,random_state=42\n",
        "          ,max_iter=10000\n",
        "          ,fit_intercept=True\n",
        "          ,solver='liblinear'\n",
        "          ,tol=10\n",
        "      )\n",
        "\n",
        "  searchCV_l1.fit(X_train, y_train)\n",
        "  searchCV_l2.fit(X_train, y_train)\n",
        "  print ('Max auc_roc for l1:', searchCV_l1.scores_[1].mean(axis=0).max())\n",
        "  print ('Max auc_roc for l2:', searchCV_l2.scores_[1].mean(axis=0).max())\n",
        "\n",
        "  print(\"Parameters for l1 regularisations\")\n",
        "  print(searchCV_l1.coef_)\n",
        "  print(searchCV_l1.intercept_) \n",
        "  print(searchCV_l1.scores_)\n",
        "\n",
        "  print(\"Parameters for l2 regularisations\")\n",
        "  print(searchCV_l2.coef_)\n",
        "  print(searchCV_l2.intercept_) \n",
        "  print(searchCV_l2.scores_)  \n",
        "\n",
        "\n",
        "  #find predicted vallues\n",
        "  y_pred_l1 = searchCV_l1.predict(X_test)\n",
        "  y_pred_l2 = searchCV_l2.predict(X_test)\n",
        "  \n",
        "\n",
        "  #Find predicted probabilities\n",
        "  y_pred_probs_l1 = searchCV_l1.predict_proba(X_test)[:,1] \n",
        "  y_pred_probs_l2 = searchCV_l2.predict_proba(X_test)[:,1] \n",
        "\n",
        "  # Accuaracy of L2/L1 models\n",
        "  Accuracy_l2 = metrics.accuracy_score(y_pred=y_pred_l2, y_true=y_test)\n",
        "  Accuracy_l1 = metrics.accuracy_score(y_pred=y_pred_l1, y_true=y_test)\n",
        "\n",
        "  print(\"Accuarcy of Logistic model with l2 regularisation : {0}\".format(Accuracy_l2))\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test, y_pred_l2)\n",
        "  print(\"classification Report\")\n",
        "  print(classification_report(y_test, y_pred_l2))\n",
        "    \n",
        "  print(\"Accuarcy of Logistic model with l1 regularisation : {0}\".format(Accuracy_l1))\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test, y_pred_l1)\n",
        "  print(\"classification Report\")\n",
        "  print(classification_report(y_test, y_pred_l1))\n",
        "\n",
        "  l2_roc_value = roc_auc_score(y_test, y_pred_probs_l2)\n",
        "  print(\"l2 roc_value: {0}\" .format(l2_roc_value))\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_probs_l2)\n",
        "  threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "  print(\"l2 threshold: {0}\".format(threshold))\n",
        "\n",
        "  roc_auc = metrics.auc(fpr, tpr)\n",
        "  print(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr,tpr,label=\"Test, auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "  \n",
        "  df_Results = df_Results.append(pd.DataFrame({'Methodology': Methodology,'Model': 'Logistic Regression with L2 Regularisation','Accuracy': Accuracy_l2,'roc_value': l2_roc_value,'threshold': threshold}, index=[0]),ignore_index= True)\n",
        "\n",
        "  l1_roc_value = roc_auc_score(y_test, y_pred_probs_l1)\n",
        "  print(\"l1 roc_value: {0}\" .format(l1_roc_value))\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_probs_l1)\n",
        "  threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "  print(\"l1 threshold: {0}\".format(threshold))\n",
        "\n",
        "  roc_auc = metrics.auc(fpr, tpr)\n",
        "  print(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr,tpr,label=\"Test, auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "  \n",
        "  df_Results = df_Results.append(pd.DataFrame({'Methodology': Methodology,'Model': 'Logistic Regression with L1 Regularisation','Accuracy': Accuracy_l1,'roc_value': l1_roc_value,'threshold': threshold}, index=[0]),ignore_index= True)\n",
        "  return df_Results"
      ],
      "metadata": {
        "id": "vIc-AGG_PcKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Created a common function to fit and predict on a KNN model\n",
        "def buildAndRunKNNModels(df_Results,Methodology, X_train,y_train, X_test, y_test ):\n",
        "\n",
        "  #create KNN model and fit the model with train dataset\n",
        "  knn = KNeighborsClassifier(n_neighbors = 5,n_jobs=16)\n",
        "  knn.fit(X_train,y_train)\n",
        "  score = knn.score(X_test,y_test)\n",
        "  print(\"model score\")\n",
        "  print(score)\n",
        "    \n",
        "  #Accuracy\n",
        "  y_pred = knn.predict(X_test)\n",
        "  KNN_Accuracy = metrics.accuracy_score(y_pred=y_pred, y_true=y_test)\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test, y_pred)\n",
        "  print(\"classification Report\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "\n",
        "  knn_probs = knn.predict_proba(X_test)[:, 1]\n",
        "  \n",
        "  #calculate roc auc\n",
        "  knn_roc_value = roc_auc_score(y_test, knn_probs)\n",
        "  print(\"KNN roc_value: {0}\" .format(knn_roc_value))\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test,knn_probs)\n",
        "  threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "  print(\"l2 threshold: {0}\".format(threshold))\n",
        "\n",
        "  roc_auc = metrics.auc(fpr,tpr)\n",
        "  print(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr,tpr,label=\"Test, auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "    \n",
        "  df_Results = df_Results.append(pd.DataFrame({'Methodology': Methodology,'Model': 'KNN','Accuracy': score,'roc_value': knn_roc_value,'threshold': threshold}, index=[0]),ignore_index= True)\n",
        "\n",
        "  return df_Results"
      ],
      "metadata": {
        "id": "8iuJgjnZPhyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Created a common function to fit and predict on a Tree models for both gini and entropy criteria\n",
        "def buildAndRunTreeModels(df_Results, Methodology, X_train,y_train, X_test, y_test ):\n",
        "  #Evaluate Decision Tree model with 'gini' & 'entropy'\n",
        "  criteria = ['gini', 'entropy'] \n",
        "  scores = {} \n",
        "    \n",
        "  for c in criteria: \n",
        "      dt = DecisionTreeClassifier(criterion = c, random_state=42) \n",
        "      dt.fit(X_train, y_train) \n",
        "      y_pred = dt.predict(X_test)\n",
        "      test_score = dt.score(X_test, y_test) \n",
        "      tree_preds = dt.predict_proba(X_test)[:, 1]\n",
        "      tree_roc_value = roc_auc_score(y_test, tree_preds)\n",
        "      scores = test_score \n",
        "      print(c + \" score: {0}\" .format(test_score))\n",
        "      print(\"Confusion Matrix\")\n",
        "      Plot_confusion_matrix(y_test, y_pred)\n",
        "      print(\"classification Report\")\n",
        "      print(classification_report(y_test, y_pred))\n",
        "      print(c + \" tree_roc_value: {0}\" .format(tree_roc_value))\n",
        "      fpr, tpr, thresholds = metrics.roc_curve(y_test, tree_preds)\n",
        "      threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "      print(\"Tree threshold: {0}\".format(threshold))\n",
        "      roc_auc = metrics.auc(fpr, tpr)\n",
        "      print(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\n",
        "      plt.plot(fpr,tpr,label=\"Test, auc=\"+str(roc_auc))\n",
        "      plt.legend(loc=4)\n",
        "      plt.show()\n",
        "  \n",
        "      df_Results = df_Results.append(pd.DataFrame({'Methodology': Methodology,'Model': 'Tree Model with {0} criteria'.format(c),'Accuracy': test_score,'roc_value': tree_roc_value,'threshold': threshold}, index=[0]),ignore_index= True)\n",
        "\n",
        "  return df_Results"
      ],
      "metadata": {
        "id": "WwdPYCHpPoHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Created a common function to fit and predict on a Random Forest model\n",
        "def buildAndRunRandomForestModels(df_Results, Methodology, X_train,y_train, X_test, y_test ):\n",
        "  #Evaluate Random Forest model\n",
        "\n",
        "  # Create the model with 100 trees\n",
        "  RF_model = RandomForestClassifier(n_estimators=100, \n",
        "                                bootstrap = True,\n",
        "                                max_features = 'sqrt', random_state=42)\n",
        "  # Fit on training data\n",
        "  RF_model.fit(X_train, y_train)\n",
        "  RF_test_score = RF_model.score(X_test, y_test)\n",
        "  RF_model.predict(X_test)\n",
        "\n",
        "  print('Model Accuracy: {0}'.format(RF_test_score))\n",
        "\n",
        "\n",
        "  # Actual class predictions\n",
        "  rf_predictions = RF_model.predict(X_test)\n",
        "\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test, rf_predictions)\n",
        "  print(\"classification Report\")\n",
        "  print(classification_report(y_test, rf_predictions))\n",
        "\n",
        "  # Probabilities for each class\n",
        "  rf_probs = RF_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  # Calculate roc auc\n",
        "  roc_value = roc_auc_score(y_test, rf_probs)\n",
        "\n",
        "  print(\"Random Forest roc_value: {0}\" .format(roc_value))\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test, rf_probs)\n",
        "  threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "  print(\"Random Forest threshold: {0}\".format(threshold))\n",
        "  roc_auc = metrics.auc(fpr, tpr)\n",
        "  print(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr,tpr,label=\"Test, auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "  \n",
        "  df_Results = df_Results.append(pd.DataFrame({'Methodology': Methodology,'Model': 'Random Forest','Accuracy': RF_test_score,'roc_value': roc_value,'threshold': threshold}, index=[0]),ignore_index= True)\n",
        "\n",
        "  return df_Results"
      ],
      "metadata": {
        "id": "JjK5851BPw2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Created a common function to fit and predict on a XGBoost model\n",
        "def buildAndRunXGBoostModels(df_Results, Methodology,X_train,y_train, X_test, y_test ):\n",
        "  #Evaluate XGboost model\n",
        "  XGBmodel = XGBClassifier(random_state=42)\n",
        "  XGBmodel.fit(X_train, y_train)\n",
        "  y_pred = XGBmodel.predict(X_test)\n",
        "\n",
        "  XGB_test_score = XGBmodel.score(X_test, y_test)\n",
        "  print('Model Accuracy: {0}'.format(XGB_test_score))\n",
        "\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test, y_pred)\n",
        "  print(\"classification Report\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  # Probabilities for each class\n",
        "  XGB_probs = XGBmodel.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  # Calculate roc auc\n",
        "  XGB_roc_value = roc_auc_score(y_test, XGB_probs)\n",
        "\n",
        "  print(\"XGboost roc_value: {0}\" .format(XGB_roc_value))\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test, XGB_probs)\n",
        "  threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "  print(\"XGBoost threshold: {0}\".format(threshold))\n",
        "  roc_auc = metrics.auc(fpr, tpr)\n",
        "  print(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr,tpr,label=\"Test, auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "  \n",
        "  df_Results = df_Results.append(pd.DataFrame({'Methodology': Methodology,'Model': 'XGBoost','Accuracy': XGB_test_score,'roc_value': XGB_roc_value,'threshold': threshold}, index=[0]),ignore_index= True)\n",
        "\n",
        "  return df_Results\n",
        " "
      ],
      "metadata": {
        "id": "v0WQy3uFP0k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Created a common function to fit and predict on a SVM model\n",
        "def buildAndRunSVMModels(df_Results, Methodology, X_train,y_train, X_test, y_test ):\n",
        "  #Evaluate SVM model with sigmoid kernel  model\n",
        "  from sklearn.svm import SVC\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "\n",
        "  clf = SVC(kernel='sigmoid', random_state=42)\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_pred_SVM = clf.predict(X_test)\n",
        "  SVM_Score = accuracy_score(y_test,y_pred_SVM)\n",
        "  print(\"accuracy_score : {0}\".format(SVM_Score))\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test, y_pred_SVM)\n",
        "  print(\"classification Report\")\n",
        "  print(classification_report(y_test, y_pred_SVM))\n",
        "\n",
        "  # Run classifier\n",
        "  classifier = SVC(kernel='sigmoid' , probability=True)\n",
        "  svm_probs = classifier.fit(X_train, y_train).predict_proba(X_test)[:, 1]\n",
        "\n",
        "  # Calculate roc auc\n",
        "  roc_value = roc_auc_score(y_test, svm_probs)\n",
        "  \n",
        "  print(\"SVM roc_value: {0}\" .format(roc_value))\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test, svm_probs)\n",
        "  threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "  print(\"SVM threshold: {0}\".format(threshold))\n",
        "  roc_auc = metrics.auc(fpr, tpr)\n",
        "  print(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr,tpr,label=\"Test, auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "  \n",
        "  df_Results = df_Results.append(pd.DataFrame({'Methodology': Methodology,'Model': 'SVM','Accuracy': SVM_Score,'roc_value': roc_value,'threshold': threshold}, index=[0]),ignore_index= True)\n",
        "\n",
        "  return df_Results"
      ],
      "metadata": {
        "id": "sREn7wEsP10S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build different models on the imbalanced dataset and see the result"
      ],
      "metadata": {
        "id": "nMvD1gz-P9BO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform cross validation with RepeatedKFold**"
      ],
      "metadata": {
        "id": "MRYoSI4xP-69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeated K-fold is the most preferred cross-validation techinque for both classification and regression machine learning model. Shuffling and random sampling of the data set multiple time is the core procdure of repeated K-fokd algorithm anfd it results in making a robust model as it covers the maximum training and testing operations."
      ],
      "metadata": {
        "id": "4LndC3TvQRb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's perform repeatedKfold and check the result\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "rkf = RepeatedKFold(n_splits=5,n_repeats=10,random_state=None)\n",
        "#X is the feature set and y is the target\n",
        "for train_index,test_index in rkf.split(X,y):\n",
        "    print(\"TRAIN\",train_index,\"Test\",test_index)\n",
        "    X_train_cv,X_test_cv = X.iloc[train_index],X.iloc[test_index]\n",
        "    y_train_cv,y_test_cv = y.iloc[train_index],y.iloc[test_index]"
      ],
      "metadata": {
        "id": "W3bWyvU_P5BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Logistic Regression with L1 And L2 Regularisation\n",
        "print(\"Logistic Regression with L1 And L2 Regularisation\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModels(df_Results,\"RepeatedKFold Cross Validation\", X_train_cv,y_train_cv, X_test_cv, y_test_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*60 )"
      ],
      "metadata": {
        "id": "dqsFt7jGQffc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run KNN Model\n",
        "print(\"KNN Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunKNNModels(df_Results,\"RepeatedKFold Cross Validation\",X_train_cv,y_train_cv, X_test_cv, y_test_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*60 )"
      ],
      "metadata": {
        "id": "ZIxiIQnVQgXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Decision Tree Models with  'gini' & 'entropy' criteria\n",
        "print(\"Decision Tree Models with  'gini' & 'entropy' criteria\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunTreeModels(df_Results,\"RepeatedKFold Cross Validation\",X_train_cv,y_train_cv, X_test_cv, y_test_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*60 )"
      ],
      "metadata": {
        "id": "-2S1J5AXQm5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Random Forest Model\n",
        "print(\"Random Forest Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunRandomForestModels(df_Results,\"RepeatedKFold Cross Validation\",X_train_cv,y_train_cv, X_test_cv, y_test_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*60 )"
      ],
      "metadata": {
        "id": "XZ1piuc8Qpem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run XGBoost Modela\n",
        "print(\"XGBoost Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunXGBoostModels(df_Results,\"RepeatedKFold Cross Validation\",X_train_cv,y_train_cv, X_test_cv, y_test_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*60 )"
      ],
      "metadata": {
        "id": "wfHW8Q2BQgjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run SVM Model with Sigmoid Kernel\n",
        "print(\"SVM Model with Sigmoid Kernel\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunSVMModels(df_Results,\"RepeatedKFold Cross Validation\",X_train_cv,y_train_cv, X_test_cv, y_test_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "gdRxjV5JQgxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the df_result dataframe which contain consolidated result of all the runs\n",
        "df_Results"
      ],
      "metadata": {
        "id": "dGSDVnxGPoa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Results for cross validation with RepeatedKFold:**\n",
        "Looking at Accuracy and ROC value we have \"Logistic Regression with L2 Regularisation\" which has provided best results for cross validation with RepeatedKFold technique"
      ],
      "metadata": {
        "id": "wSKMVYpKRg-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Perform cross validation with StratifiedKFold**"
      ],
      "metadata": {
        "id": "OIQxJzO1SjT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets perfrom StratifiedKFold and check the results\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
        "# X is the feature set and y is the target\n",
        "for train_index, test_index in skf.split(X,y):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train_SKF_cv, X_test_SKF_cv = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_SKF_cv, y_test_SKF_cv = y.iloc[train_index], y.iloc[test_index]"
      ],
      "metadata": {
        "id": "_CuVQyIYRdb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Logistic Regression with L1 And L2 Regularisation\n",
        "print(\"Logistic Regression with L1 And L2 Regularisation\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModels(df_Results,\"StratifiedKFold Cross Validation\", X_train_SKF_cv,y_train_SKF_cv, X_test_SKF_cv, y_test_SKF_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*60 )"
      ],
      "metadata": {
        "id": "9n6i2xNRPcYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run KNN Model\n",
        "print(\"KNN Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunKNNModels(df_Results,\"StratifiedKFold Cross Validation\",X_train_SKF_cv,y_train_SKF_cv, X_test_SKF_cv, y_test_SKF_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*60 )"
      ],
      "metadata": {
        "id": "LZbRxaf0Sydx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Decision Tree Models with  'gini' & 'entropy' criteria\n",
        "print(\"Decision Tree Models with  'gini' & 'entropy' criteria\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunTreeModels(df_Results,\"StratifiedKFold Cross Validation\",X_train_SKF_cv,y_train_SKF_cv, X_test_SKF_cv, y_test_SKF_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*60 )"
      ],
      "metadata": {
        "id": "4kKZOdhPSzO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Random Forest Model\n",
        "print(\"Random Forest Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunRandomForestModels(df_Results,\"StratifiedKFold Cross Validation\",X_train_SKF_cv,y_train_SKF_cv, X_test_SKF_cv, y_test_SKF_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*60 )"
      ],
      "metadata": {
        "id": "2Ui6PFuhS2d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run XGBoost Modela\n",
        "print(\"XGBoost Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunXGBoostModels(df_Results,\"StratifiedKFold Cross Validation\",X_train_SKF_cv,y_train_SKF_cv, X_test_SKF_cv, y_test_SKF_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*60 )"
      ],
      "metadata": {
        "id": "ARqt6ZWtS9yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run SVM Model with Sigmoid Kernel\n",
        "print(\"SVM Model with Sigmoid Kernel\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunSVMModels(df_Results,\"StratifiedKFold Cross Validation\",X_train_SKF_cv,y_train_SKF_cv, X_test_SKF_cv, y_test_SKF_cv)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "tFD1gHGETCNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the df_result dataframe which contain consolidated result of all the runs\n",
        "df_Results"
      ],
      "metadata": {
        "id": "ZGlo4NHaPcgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results for cross validation with StratifiedKFold:\n",
        "Looking at the ROC value we have Logistic Regression with L2 Regularisation has provided best results for cross validation with StratifiedKFold technique"
      ],
      "metadata": {
        "id": "0tms-uiSTOLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conclusion : \n",
        "- As the results show Logistic Regression with L2 Regularisation for StratifiedKFold cross validation provided best results"
      ],
      "metadata": {
        "id": "8NWBhGWrTh_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Proceed with the model which shows the best result \n",
        "- Apply the best hyperparameter on the model\n",
        "- Predict on the test dataset"
      ],
      "metadata": {
        "id": "PhKuSlVET2Pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "from sklearn import linear_model #import the package\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "num_C = list(np.power(10.0, np.arange(-10, 10)))\n",
        "cv_num = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "clf = linear_model.LogisticRegressionCV(\n",
        "          Cs= num_C\n",
        "          ,penalty='l2'\n",
        "          ,scoring='roc_auc'\n",
        "          ,cv=cv_num\n",
        "          ,random_state=42\n",
        "          ,max_iter=10000\n",
        "          ,fit_intercept=True\n",
        "          ,solver='newton-cg'\n",
        "          ,tol=10\n",
        "      )\n",
        "\n",
        "clf.fit(X_train_SKF_cv, y_train_SKF_cv)\n",
        "print ('Max auc_roc for l2:', clf.scores_[1].mean(axis=0).max())\n",
        "\n",
        "\n",
        "print(\"Parameters for l2 regularisations\")\n",
        "print(clf.coef_)\n",
        "print(clf.intercept_) \n",
        "print(clf.scores_) \n",
        "\n",
        "\n",
        "#find predicted vallues\n",
        "y_pred_l2 = clf.predict(X_test)\n",
        "\n",
        "\n",
        "#Find predicted probabilities\n",
        "y_pred_probs_l2 = clf.predict_proba(X_test)[:,1] \n",
        "\n",
        "\n",
        "# Accuaracy of L2/L1 models\n",
        "Accuracy_l2 = metrics.accuracy_score(y_pred=y_pred_l2, y_true=y_test)\n",
        "\n",
        "\n",
        "print(\"Accuarcy of Logistic model with l2 regularisation : {0}\".format(Accuracy_l2))\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "l2_roc_value = roc_auc_score(y_test, y_pred_probs_l2)\n",
        "print(\"l2 roc_value: {0}\" .format(l2_roc_value))\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_probs_l2)\n",
        "threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "print(\"l2 threshold: {0}\".format(threshold))"
      ],
      "metadata": {
        "id": "GiVS5srWPcvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for the coefficient values\n",
        "clf.coef_"
      ],
      "metadata": {
        "id": "1xqeJPAkOnxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dataframe with the coefficient values\n",
        "coefficients = pd.concat([pd.DataFrame(X.columns),pd.DataFrame(np.transpose(clf.coef_))], axis = 1)\n",
        "coefficients.columns = ['Feature','Importance Coefficient']"
      ],
      "metadata": {
        "id": "uVJXJGKzUB3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefficients"
      ],
      "metadata": {
        "id": "1HGD1L4rUEM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print the important features of the best model to understand the dataset\n",
        "- This will not give much explanation on the already transformed dataset\n",
        "- But it will help us in understanding if the dataset is not PCA transformed"
      ],
      "metadata": {
        "id": "6YrO_bB4UKzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the coefficient values\n",
        "plt.figure(figsize=(20,5))\n",
        "sns.barplot(x='Feature', y='Importance Coefficient', data=coefficients)\n",
        "plt.title(\"Logistic Regression with L2 Regularisation Feature Importance\", fontsize=18)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bf3uGEVIUGI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence it implies that V4, v5,V11 has + ve importance whereas V10, V12, V14 seems to have -ve impact on the predictaions"
      ],
      "metadata": {
        "id": "eYrUeyOBU6ut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model building with balancing Classes\n",
        "\n",
        "##### Perform class balancing with :\n",
        "- Random Oversampling\n",
        "- SMOTE\n",
        "- ADASYN"
      ],
      "metadata": {
        "id": "1r4JLcimU8Uk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Oversampling with SMOTE Oversampling**"
      ],
      "metadata": {
        "id": "50XY3yfBaZw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use SMOTE Oversampling method to handle the class imbalance"
      ],
      "metadata": {
        "id": "SORx8Xg2aX1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataframe with Smote and StratifiedKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn import over_sampling\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X,y), 1):\n",
        "    X_train = X.loc[train_index]\n",
        "    y_train = y.loc[train_index] \n",
        "    X_test = X.loc[test_index]\n",
        "    y_test = y.loc[test_index]  \n",
        "    SMOTE = over_sampling.SMOTE(random_state=0)\n",
        "    X_train_Smote, y_train_Smote= SMOTE.fit_resample(X_train, y_train)\n",
        "  \n",
        "X_train_Smote = pd.DataFrame(data=X_train_Smote,   columns=cols)"
      ],
      "metadata": {
        "id": "aLSp6ikpUGVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data_Imbalance_Handiling\t = \"SMOTE Oversampling with StratifiedKFold CV \"\n",
        "#Run Logistic Regression with L1 And L2 Regularisation\n",
        "print(\"Logistic Regression with L1 And L2 Regularisation\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModels(df_Results, Data_Imbalance_Handiling, X_train_Smote, y_train_Smote , X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*80 )"
      ],
      "metadata": {
        "id": "govAaxxYU2aW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run KNN Model\n",
        "print(\"KNN Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunKNNModels(df_Results, Data_Imbalance_Handiling, X_train_Smote, y_train_Smote , X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*80 )\n"
      ],
      "metadata": {
        "id": "sl7pFScRZyVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Decision Tree Models with  'gini' & 'entropy' criteria\n",
        "print(\"Decision Tree Models with  'gini' & 'entropy' criteria\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunTreeModels(df_Results, Data_Imbalance_Handiling, X_train_Smote, y_train_Smote , X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*80 )"
      ],
      "metadata": {
        "id": "mCnYbPBoZ1xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Random Forest Model\n",
        "print(\"Random Forest Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunRandomForestModels(df_Results, Data_Imbalance_Handiling, X_train_Smote, y_train_Smote , X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*80 )"
      ],
      "metadata": {
        "id": "cbodCn47Z4x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run XGBoost Model\n",
        "print(\"XGBoost Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunXGBoostModels(df_Results, Data_Imbalance_Handiling, X_train_Smote, y_train_Smote , X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*80 )"
      ],
      "metadata": {
        "id": "770wQv33Z6xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the df_result dataframe which contains consolidated results of all the runs\n",
        "df_Results"
      ],
      "metadata": {
        "id": "VXsfFgYIe_sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Results for SMOTE Oversampling with StratifiedKFold:**\n",
        "Looking at Accuracy and ROC value we have XGBoost which has provided best results for SMOTE Oversampling with StratifiedKFold technique "
      ],
      "metadata": {
        "id": "iQI60pvBfBn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Oversampling with ADASYN Oversampling**"
      ],
      "metadata": {
        "id": "5C_TMGPvfS09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We will use ADASYN Oversampling method to handle the class imbalance"
      ],
      "metadata": {
        "id": "EBImVd61feNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataframe with ADASYN and StratifiedKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn import over_sampling\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X,y), 1):\n",
        "    X_train = X.loc[train_index]\n",
        "    y_train = y.loc[train_index] \n",
        "    X_test = X.loc[test_index]\n",
        "    y_test = y.loc[test_index]  \n",
        "    ADASYN = over_sampling.ADASYN(random_state=0)\n",
        "    X_train_ADASYN, y_train_ADASYN= ADASYN.fit_resample(X_train, y_train)\n",
        "  \n",
        "X_train_ADASYN = pd.DataFrame(data=X_train_ADASYN,   columns=cols)"
      ],
      "metadata": {
        "id": "odn6a-cUfaup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data_Imbalance_Handiling\t = \"ADASYN Oversampling with StratifiedKFold CV \"\n",
        "#Run Logistic Regression with L1 And L2 Regularisation\n",
        "print(\"Logistic Regression with L1 And L2 Regularisation\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModels(df_Results, Data_Imbalance_Handiling, X_train_ADASYN, y_train_ADASYN , X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*80 )"
      ],
      "metadata": {
        "id": "mCy7FbSKfQxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run KNN Model\n",
        "print(\"KNN Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunKNNModels(df_Results, Data_Imbalance_Handiling,X_train_ADASYN, y_train_ADASYN , X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*80 )"
      ],
      "metadata": {
        "id": "9n1clvCXfKNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Decision Tree Models with  'gini' & 'entropy' criteria\n",
        "print(\"Decision Tree Models with  'gini' & 'entropy' criteria\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunTreeModels(df_Results, Data_Imbalance_Handiling,X_train_ADASYN, y_train_ADASYN , X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*80 )"
      ],
      "metadata": {
        "id": "lt8MXMdDf6Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Random Forest Model\n",
        "print(\"Random Forest Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunRandomForestModels(df_Results, Data_Imbalance_Handiling,X_train_ADASYN, y_train_ADASYN , X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*80 )"
      ],
      "metadata": {
        "id": "Ks41ady1f_UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run XGBoost Model\n",
        "print(\"XGBoost Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunXGBoostModels(df_Results, Data_Imbalance_Handiling,X_train_ADASYN, y_train_ADASYN , X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*80 )"
      ],
      "metadata": {
        "id": "6E878bzIgCf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the df_result dataframe which contains consolidated results of all the runs\n",
        "df_Results"
      ],
      "metadata": {
        "id": "Xke8Av3agTWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results for ADASYN  Oversampling with StratifiedKFold: \n",
        "Looking at Accuracy and ROC value we have XGBoost which has provided best results for ADASYN Oversampling with StratifiedKFold technique "
      ],
      "metadata": {
        "id": "xRly4pA5iOH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Oversampling with RandomOverSampler with StratifiedKFold Cross Validation**\n",
        "- We will use Random Oversampling method to handle the class imbalance"
      ],
      "metadata": {
        "id": "CmbjQLS5g4uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the dataset with RandomOverSampler and StratifiedKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X,y), 1):\n",
        "    X_train = X.loc[train_index]\n",
        "    y_train = y.loc[train_index] \n",
        "    X_test = X.loc[test_index]\n",
        "    y_test = y.loc[test_index]  \n",
        "    ROS = RandomOverSampler(sampling_strategy=0.5)\n",
        "    X_over, y_over= ROS.fit_resample(X_train, y_train)\n",
        "  \n",
        "X_over = pd.DataFrame(data=X_over, columns=cols)"
      ],
      "metadata": {
        "id": "CACtAwiPhV9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data_Imbalance_Handiling\t = \"Random Oversampling with StratifiedKFold CV \"\n",
        "#Run Logistic Regression with L1 And L2 Regularisation\n",
        "print(\"Logistic Regression with L1 And L2 Regularisation\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModels(df_Results , Data_Imbalance_Handiling , X_over, y_over, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*60 )"
      ],
      "metadata": {
        "id": "wl4GsH4rhYkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Run KNN Model\n",
        "print(\"KNN Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunKNNModels(df_Results , Data_Imbalance_Handiling,X_over, y_over, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*60 )"
      ],
      "metadata": {
        "id": "pOLZPWZIheBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Decision Tree Models with  'gini' & 'entropy' criteria\n",
        "print(\"Decision Tree Models with  'gini' & 'entropy' criteria\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunTreeModels(df_Results , Data_Imbalance_Handiling,X_over, y_over, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*60 )"
      ],
      "metadata": {
        "id": "KLgRhKdfhgPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Random Forest Model\n",
        "print(\"Random Forest Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunRandomForestModels(df_Results , Data_Imbalance_Handiling,X_over, y_over, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*60 )"
      ],
      "metadata": {
        "id": "p3T1Hu1shi48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run XGBoost Model\n",
        "print(\"XGBoost Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunXGBoostModels(df_Results , Data_Imbalance_Handiling,X_over, y_over, X_test, y_test)\n",
        "print(\"Time Taken by Model: --- %s seconds ---\" % (time.time() - start_time))\n",
        "print('-'*60 )"
      ],
      "metadata": {
        "id": "7vUX8EyGhlfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results for Random Oversampling with StratifiedKFold technique:\n",
        "Looking at the Accuracy and ROC value we have XGBoost which has provided best results for Random Oversampling and StratifiedKFold technique"
      ],
      "metadata": {
        "id": "f23HKgGBh07Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overall conclusion after running the models on Oversampled data :\n",
        "Looking at above results it seems XGBOOST model with Random Oversampling with StratifiedKFold CV has provided the best results under the category of all oversampling techniques. So we will try to tune the hyperparameters of this model to get best results."
      ],
      "metadata": {
        "id": "tNY09UG8h1Hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "o9s_qgC0i-R4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HPT - Xgboost Regression"
      ],
      "metadata": {
        "id": "_Js9ZepZjCRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing Hyperparameter tuning\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
        "param_test = {\n",
        " 'max_depth':range(3,10,2),\n",
        " 'min_child_weight':range(1,6,2),\n",
        " 'n_estimators':range(60,130,150),\n",
        " 'learning_rate':[0.05,0.1,0.125,0.15,0.2],\n",
        " 'gamma':[i/10.0 for i in range(0,5)],\n",
        " 'subsample':[i/10.0 for i in range(7,10)],\n",
        " 'colsample_bytree':[i/10.0 for i in range(7,10)]\n",
        "}\n",
        "\n",
        "gsearch1 = RandomizedSearchCV(estimator = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1,max_delta_step=0,\n",
        "              missing=None, n_jobs=-1,\n",
        "              nthread=None, objective='binary:logistic', random_state=42,\n",
        "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "              silent=None, verbosity=1), \n",
        "              param_distributions = param_test, n_iter=5,scoring='roc_auc',n_jobs=-1, cv=5)\n",
        "\n",
        "gsearch1.fit(X_over, y_over)\n",
        "gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_"
      ],
      "metadata": {
        "id": "MAGloUD0hrEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please note that the hyperparameters found above using RandomizedSearchCV and the hyperparameters used below in creating the final model might be different, the reason being, I have executed the RandomizedSearchCV multiple times to find which set of hyperparameters gives the optimum result and finally used the one below which gave me the best performance."
      ],
      "metadata": {
        "id": "Jq6NsLXqjTQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating XGBoost model with selected hyperparameters\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "clf = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=0.7, gamma=0.2,\n",
        "              learning_rate=0.125, max_delta_step=0, max_depth=7,\n",
        "              min_child_weight=5, missing=None, n_estimators=60, n_jobs=1,\n",
        "              nthread=None, objective='binary:logistic', random_state=42,\n",
        "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "              silent=None, subsample=0.8, verbosity=1)\n",
        "\n",
        "# fit on the dataset\n",
        "clf.fit(X_over, y_over ) \n",
        "XGB_test_score = clf.score(X_test, y_test)\n",
        "print('Model Accuracy: {0}'.format(XGB_test_score))\n",
        "\n",
        "# Probabilities for each class\n",
        "XGB_probs = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate roc auc\n",
        "XGB_roc_value = roc_auc_score(y_test, XGB_probs)\n",
        "\n",
        "print(\"XGboost roc_value: {0}\" .format(XGB_roc_value))\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, XGB_probs)\n",
        "threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "print(\"XGBoost threshold: {0}\".format(threshold))"
      ],
      "metadata": {
        "id": "S035XWfHjUXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print the important features of the best model to understand the dataset"
      ],
      "metadata": {
        "id": "sSzxUd0jjdzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imp_var = []\n",
        "for i in clf.feature_importances_:\n",
        "    imp_var.append(i)\n",
        "print('Top var =', imp_var.index(np.sort(clf.feature_importances_)[-1])+1)\n",
        "print('2nd Top var =', imp_var.index(np.sort(clf.feature_importances_)[-2])+1)\n",
        "print('3rd Top var =', imp_var.index(np.sort(clf.feature_importances_)[-3])+1)"
      ],
      "metadata": {
        "id": "IacfZe8Cjeuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate roc auc\n",
        "XGB_roc_value = roc_auc_score(y_test, XGB_probs)\n",
        "\n",
        "print(\"XGboost roc_value: {0}\" .format(XGB_roc_value))\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, XGB_probs)\n",
        "threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "print(\"XGBoost threshold: {0}\".format(threshold))"
      ],
      "metadata": {
        "id": "Zy4LCiabjhxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusion**\n",
        "\n",
        "In the oversample cases, of all the models we build found that the XGBOOST model with Random Oversampling with StratifiedKFold CV gave us the best accuracy and ROC on oversampled data. Post that we performed hyperparameter tuning and got the below metrices : \n",
        "\n",
        "XGboost roc_value: 0.9815403079438694\n",
        "XGBoost threshold: 0.01721232570707798\n",
        "\n",
        "However, of all the models we created we found Logistic Regression with L2 Regularisation for StratifiedKFold cross validation (without any oversampling or undersampling) gave us the best result."
      ],
      "metadata": {
        "id": "vQHRI3GMjldt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ad-Z9ZSDjcr0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}